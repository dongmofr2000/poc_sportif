import pandas as pd
import numpy as np
from sqlalchemy import create_engine
import requests
import sys

# ==============================================================================
# 0. CONFIGURATION & CONNEXION
# ==============================================================================

# Identifiants PostgreSQL
DB_USER = "postgres"
DB_PASS = "Yaounde0123@"
DB_HOST = "127.0.0.1"
DB_PORT = "5432"
DB_NAME = "sport_projet"
DB_URL = f"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# Param√®tres du projet
PRIME_RATE = 0.05
MIN_ACTIVITES = 15
SLACK_WEBHOOK_URL = "https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX"

# Noms des fichiers
RH_FILE = "donnees_rh.csv"
ACTIVITES_FILE = "activites_simulees.csv"


def get_db_engine():
    """Initialise et retourne le moteur SQLAlchemy."""
    print(f"Tentative de connexion √† la base de donn√©es {DB_NAME}...")
    try:
        engine = create_engine(
            'postgresql+psycopg2://',
            connect_args={
                'host': DB_HOST,
                'port': DB_PORT,
                'database': DB_NAME,
                'user': DB_USER,
                'password': DB_PASS
            }
        )
        
        with engine.connect() as connection:
            print(f"‚úÖ Connexion √† la base de donn√©es {DB_NAME} √©tablie avec succ√®s.")
        return engine
    except Exception as e:
        print(f"‚ùå ERREUR : √âchec de la connexion √† la base de donn√©es. D√©tail : {e}")
        sys.exit(1)


# ==============================================================================
# 1. EXTRACTION (E)
# ==============================================================================

def extract_data():
    """Charge les donn√©es RH et d'activit√©s depuis les fichiers CSV."""
    print("‚è≥ √âtape E (Extraction) : Chargement des donn√©es...")
    try:
        # Fichier RH: S√©parateur ';' et Encodage 'latin-1'
        df_rh = pd.read_csv(RH_FILE, sep=';', encoding='latin-1')
        print(f"   -> Fichier RH charg√© : {len(df_rh)} lignes.")

        # Fichier Activit√©s: S√©parateur ',' et encodage 'utf-8'
        df_activites = pd.read_csv(ACTIVITES_FILE, sep=',', encoding='utf-8')
        print(f"   -> Fichier Activit√©s charg√© : {len(df_activites)} lignes.")

        return df_rh, df_activites
    except FileNotFoundError as e:
        print(f"‚ùå ERREUR : Fichier non trouv√©. Assurez-vous que '{e.filename}' est dans le bon dossier.")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå ERREUR lors de la lecture des fichiers CSV : {e}")
        sys.exit(1)

# ==============================================================================
# 2. TRANSFORMATION (T)
# ==============================================================================

def transform_data(df_rh, df_activites):
    """Effectue le nettoyage, le calcul des primes, et le filtrage des donn√©es."""
    print("‚è≥ √âtape T (Transformation) : Nettoyage et calculs...")

    try:
        # --- Nettoyage des Noms de Colonnes (AGRESSIF) ---
        def clean_cols(df):
            cols = df.columns.str.lower().str.strip()
            # 1. Remplacer tous les caract√®res non alphanum√©riques (sauf underscore) par un underscore
            cols = cols.str.replace(r'[^a-z0-9_]+', '_', regex=True)
            # 2. Supprimer les underscores multiples
            cols = cols.str.replace('__', '_', regex=False)
            # 3. Supprimer les accents
            cols = cols.str.replace('√©', 'e', regex=False).str.replace('√®', 'e', regex=False).str.replace('√™', 'e', regex=False).str.replace('√†', 'a', regex=False).str.replace('√Æ', 'i', regex=False)
            
            df.columns = cols
            return df

        df_rh = clean_cols(df_rh)
        df_activites = clean_cols(df_activites)
        
        # 2. Renommage des colonnes nettoy√©es (Adapt√© aux sorties console finales)
        
        # Renommage RH 
        df_rh.rename(columns={
            # ID Salari√© RH
            'id_salari_': 'collaborateur_id', 
            'salaire_brut': 'salaire',
            'moyen_de_d_placement': 'moyen_deplacement' 
        }, inplace=True)
        
        # Renommage Activit√©s
        df_activites.rename(columns={
            # ID Salari√© Activit√©s (m√™me nom apr√®s nettoyage que RH)
            'id_salari_': 'collaborateur_id', 
            # Type d'activit√© (Bas√© sur la sortie console: type_d_activit_)
            'type_d_activit_': 'activite'
        }, inplace=True)
        
        # --- GESTION DE LA DISTANCE MANQUANTE DANS LE FICHIER RH ---
        DISTANCE_COL_NAME = 'distance_domicile_travail_km'
        if DISTANCE_COL_NAME not in df_rh.columns:
            print(f"‚ö†Ô∏è Avertissement: Colonne '{DISTANCE_COL_NAME}' non trouv√©e dans RH. Ajout d'une distance fictive (5 km) pour le test.")
            df_rh[DISTANCE_COL_NAME] = 5.0
        
        # V√©rification finale des colonnes critiques
        if 'collaborateur_id' not in df_rh.columns or 'salaire' not in df_rh.columns or 'moyen_deplacement' not in df_rh.columns:
             print(f"Colonnes RH trouv√©es: {df_rh.columns.tolist()}")
             raise KeyError("Colonnes RH critiques manquantes apr√®s renommage.")
        # La colonne 'activite' existe dans df_activites gr√¢ce au renommage ci-dessus.
        if 'collaborateur_id' not in df_activites.columns or 'activite' not in df_activites.columns:
            print(f"Colonnes Activit√©s trouv√©es: {df_activites.columns.tolist()}")
            raise KeyError("Colonnes Activit√©s critiques manquantes apr√®s renommage.")
        
        
        # --- Logique Commune ---
        df_rh['collaborateur_id'] = df_rh['collaborateur_id'].astype(str).str.lower()
        df_activites['collaborateur_id'] = df_activites['collaborateur_id'].astype(str).str.lower()


        # =========================================================
        # CALCUL 1: √âligibilit√© aux 5 Jours "Bien-√™tre" (R√®gle 15 activit√©s)
        # =========================================================
        # Regrouper par collaborateur_id et compter les 'activite'
        df_total_activites = df_activites.groupby('collaborateur_id')['activite'].count().reset_index(name='total_activites')

        df_final = pd.merge(df_rh, df_total_activites, on='collaborateur_id', how='left')
        df_final['total_activites'] = df_final['total_activites'].fillna(0).astype(int)

        df_final['eligibilite_jours_bien_etre'] = (df_final['total_activites'] >= MIN_ACTIVITES)
        
        
        # =========================================================
        # CALCUL 2: √âligibilit√© √† la Prime Sportive (R√®gle Mode de D√©placement et Distance)
        # =========================================================
        
        # 1. D√©finir les d√©placements consid√©r√©s comme "sportifs"
        sports_navette = ['velo', 'trottinette', 'marche/running', 'autres']
        df_final['moyen_deplacement_clean'] = df_final['moyen_deplacement'].astype(str).str.lower().str.strip()
        
        df_final['is_sportif'] = df_final['moyen_deplacement_clean'].apply(lambda x: any(sport in x for sport in sports_navette))
        
        # 2. V√©rifier les plafonds de distance (Max 15/25 km)
        def valider_distance(row):
            dist = row[DISTANCE_COL_NAME]
            moyen = row['moyen_deplacement_clean']
            
            if not row['is_sportif']:
                return False
            
            if 'marche/running' in moyen:
                return dist <= 15 
            elif any(x in moyen for x in ['velo', 'trottinette', 'autres']):
                return dist <= 25 
            else:
                return True
        
        df_final['distance_validee'] = df_final.apply(valider_distance, axis=1)

        # 3. Calcul de l'√©ligibilit√© finale √† la prime
        df_final['eligibilite_prime'] = df_final['is_sportif'] & df_final['distance_validee']

        # 4. Calcul de la prime (5% du Salaire Brut)
        df_final['prime_brute'] = df_final['salaire'] * PRIME_RATE
        
        df_final['montant_prime'] = np.where(
            df_final['eligibilite_prime'], 
            df_final['prime_brute'], 
            0.0
        )
        
        # --- Calculs Finaux pour le Reporting ---
        df_final['nouveau_salaire'] = df_final['salaire'] + df_final['montant_prime']

        # --- Filtrage (S√©lection des colonnes finales) ---
        df_resultat = df_final[[
            'collaborateur_id', 
            'salaire', 
            'total_activites', 
            'eligibilite_jours_bien_etre',
            'eligibilite_prime',           
            'montant_prime',
            'nouveau_salaire'
        ]].copy()
        
        # Mise en forme des montants mon√©taires
        df_resultat['salaire'] = df_resultat['salaire'].round(2)
        df_resultat['montant_prime'] = df_resultat['montant_prime'].round(2)
        df_resultat['nouveau_salaire'] = df_resultat['nouveau_salaire'].round(2)

        print(f"   -> Transformation termin√©e. {len(df_resultat)} lignes pr√™tes √† √™tre charg√©es.")
        return df_resultat
    
    except KeyError as e:
        print(f"‚ùå ERREUR KEYERROR lors de la transformation. La colonne {e} est manquante.")
        sys.exit(1)
        
# ==============================================================================
# 3. CHARGEMENT (L)
# ==============================================================================

def load_data(df_resultat, engine):
    """Charge le DataFrame final dans PostgreSQL."""
    print("‚è≥ √âtape L (Chargement) : Transfert vers PostgreSQL...")

    table_name = 'salaires_primes'

    try:
        df_resultat.to_sql(
            name=table_name,
            con=engine,
            if_exists='replace',
            index=False,
            method='multi'
        )
        print(f"‚úÖ Chargement termin√©. Les donn√©es sont dans la table '{table_name}' de la base '{DB_NAME}'.")

    except Exception as e:
        print(f"‚ùå ERREUR lors du chargement dans PostgreSQL : {e}")
        sys.exit(1)

# ==============================================================================
# 4. NOTIFICATION (SLACK)
# ==============================================================================

def send_slack_notification(df_resultat):
    """Envoie une notification de succ√®s avec les statistiques cl√©s √† Slack."""
    
    total_employes = len(df_resultat)
    primes_attribuees = (df_resultat['montant_prime'] > 0).sum()
    montant_total_primes = df_resultat['montant_prime'].sum()
    
    message = {
        "text": f"‚úÖ PIPELINE ETL/ELT SPORTIF - SUCC√àS\n\n"
                f"*Statistiques de l'ex√©cution :*\n"
                f"‚Ä¢ Collaborateurs totaux : {total_employes}\n"
                f"‚Ä¢ Primes attribu√©es (√©ligibilit√© prime) : {primes_attribuees}\n"
                f"‚Ä¢ Montant total des primes vers√©es : {montant_total_primes:,.2f} ‚Ç¨"
    }

    try:
        if SLACK_WEBHOOK_URL.endswith("XXXXXXXXXXXXXXXXXXXXXXXX"):
             print("‚ö†Ô∏è Avertissement : URL Slack par d√©faut. Notification non envoy√©e.")
             return

        response = requests.post(SLACK_WEBHOOK_URL, json=message)
        if response.status_code == 200:
            print("‚úÖ Notification Slack envoy√©e avec succ√®s.")
        else:
            print(f"‚ö†Ô∏è Avertissement : √âchec de l'envoi Slack (Code: {response.status_code})")
            
    except requests.exceptions.RequestException as e:
        print(f"‚ö†Ô∏è Avertissement : Impossible de se connecter √† Slack : {e}")
        
# ==============================================================================
# 5. FONCTION PRINCIPALE (MAIN)
# ==============================================================================

def main():
    """Fonction principale pour orchestrer le pipeline ETL/ELT."""
    print("üöÄ D√âMARRAGE DU PIPELINE ETL/ELT SPORTIF (Python/Pandas)")
    
    # 1. Connexion √† la base de donn√©es
    engine = get_db_engine()
    
    # 2. Extraction
    df_rh, df_activites = extract_data()
    
    # 3. Transformation
    df_resultat = transform_data(df_rh, df_activites)
    
    # 4. Chargement
    load_data(df_resultat, engine)
    
    # 5. Notification
    send_slack_notification(df_resultat)
    
    print("üéâ PIPELINE TERMIN√â AVEC SUCC√àS.")


if __name__ == "__main__":
    main()